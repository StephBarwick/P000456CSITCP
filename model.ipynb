{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P000456CSITCP - Hate Speech Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This will be a summary of the entire jupyternotebook* I will do this at the end :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Dataset \n",
    "\n",
    "- The twitter.csv file is loaded into the variable name data. This is then used to condut initial analysis onthe data.\n",
    "- The variables on this csv file are unamed, count, hate_speech, offensive_language, neither and class. \n",
    "\n",
    "Below is a list explaining each variable \n",
    "- count: The total number of annotations for each tweet. (Integer) </br>\n",
    "- hate_speech: The number of annotations classifying a tweet as hate speech. (Integer)</br>\n",
    "- offensive_language_count: The number of annotations classifying a tweet as offensive language. (Integer)</br>\n",
    "- neither_count: The number of annotations classifying a tweet as neither hate speech nor offensive language. (Integer)</br>\n",
    "- class: The level of hate in which the twitter comment is projecting; hate speech, offensive language or neither. (Integer) </br>\n",
    "- tweet: The tweet which the classfications are being made (String) </br>\n",
    "\n",
    "NOTE: The Unnamed column looks to be an index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('twitter.csv')\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19190\n",
       "2     4163\n",
       "0     1430\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To really understand the level of hate in which the dataset entials the class variable in looked into further. It can be said that 'class' 1 has the most counts followed by 'class' 2 then 3. \n",
    "\n",
    "The class column indicates \n",
    "- 0: Hate Speech \n",
    "- 1: Offesnive Language\n",
    "- 2: Neither "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12681.192027</td>\n",
       "      <td>3.243473</td>\n",
       "      <td>0.280515</td>\n",
       "      <td>2.413711</td>\n",
       "      <td>0.549247</td>\n",
       "      <td>1.110277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7299.553863</td>\n",
       "      <td>0.883060</td>\n",
       "      <td>0.631851</td>\n",
       "      <td>1.399459</td>\n",
       "      <td>1.113299</td>\n",
       "      <td>0.462089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6372.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12703.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18995.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25296.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         count   hate_speech  offensive_language  \\\n",
       "count  24783.000000  24783.000000  24783.000000        24783.000000   \n",
       "mean   12681.192027      3.243473      0.280515            2.413711   \n",
       "std     7299.553863      0.883060      0.631851            1.399459   \n",
       "min        0.000000      3.000000      0.000000            0.000000   \n",
       "25%     6372.500000      3.000000      0.000000            2.000000   \n",
       "50%    12703.000000      3.000000      0.000000            3.000000   \n",
       "75%    18995.500000      3.000000      0.000000            3.000000   \n",
       "max    25296.000000      9.000000      7.000000            9.000000   \n",
       "\n",
       "            neither         class  \n",
       "count  24783.000000  24783.000000  \n",
       "mean       0.549247      1.110277  \n",
       "std        1.113299      0.462089  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      1.000000  \n",
       "50%        0.000000      1.000000  \n",
       "75%        0.000000      1.000000  \n",
       "max        9.000000      2.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the statistical analysis of each variable (excluding count and unamed) it can be said that:\n",
    "\n",
    "- hate_speech: With a mean of 0.28 it can be said that most entries have low levels of hate_speech and thus most likely not being classified as hate speech. Aditionally with a 0.0 distibrution for the 25, 50 and 75 percentile show no hate speech in the data points. With a max of 7 it can highlight some entires of high levels of hate speech \n",
    "\n",
    "- offesnive_language: A mean of 2.41 shows a higher average than hate_speech and can therefore be said that offensive language is more common than hate speech. It can be noted that half of the data had a score of 3 or lower for offensive langauge. Some entires also show high levels of offensive language with a max value of 9. \n",
    "\n",
    "- neither: The mean od 0.55 shows a good portion of the data is neither hate speech or offensive language. Aditionally with a 0.0 distibrution for the 25, 50 and 75 percentile show that the data falls into other categories. Some entires also show high levels of neither category with a max value of 9. \n",
    "\n",
    "- class: 1.11 mean shows most enties are classified as offensive langauge (1). This can be shown with the 25th and 50th percentiles being 1. The max value of 2 shows that hate speech is present but less common. \n",
    "\n",
    "Ultimately the data is skewed towards offensive language. A larger proportion of the data can be seen to be offensive language as seen by the class in comparison to hate speech and a small group within neither."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "count                 0\n",
       "hate_speech           0\n",
       "offensive_language    0\n",
       "neither               0\n",
       "class                 0\n",
       "tweet                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can also be seen that there are no n/a data within any of the variables and no duplicated data in the dataset as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='class', ylabel='Count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of the classes\n",
    "sns.histplot(data['class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the histogram it can be reinstated that the offensive langauge category is classfied heavily in the dataset followed by approximately 25% of the data classfied as neither and hate speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for team - should we add in TwitterHate.csv to help balance our classes here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "- The data preprocessing stage is important to turn the raw data (twitter.csv) into clean data that can then be used for training and testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps that must be taken after the intial data analysis is data preprocessing. Here the dataset is taken and the following elements are removed from the dataset: \n",
    "\n",
    "- urls\n",
    "- usernames (especially for anonymity)\n",
    "- emojis\n",
    "- punctuation\n",
    "- single characters + double spaces\n",
    "\n",
    "The following are processed to ensure clarity in the data:\n",
    "\n",
    "- Turning everything lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processed=data[['tweet','class']]\n",
    "data_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/2544297350.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_processed[\"tweet\"] = data_processed[\"tweet\"].apply(lambda x:re.sub(r'https?://\\S+', '', str(x)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1        !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "2        !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "3        !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "4        !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
       "                               ...                        \n",
       "24778    you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
       "24779    you've gone and broke the wrong heart baby, an...\n",
       "24780    young buck wanna eat!!.. dat nigguh like I ain...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782    ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the urls\n",
    "data_processed[\"tweet\"] = data_processed[\"tweet\"].apply(lambda x:re.sub(r'https?://\\S+', '', str(x)))\n",
    "data_processed[\"tweet\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/1831671013.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_processed['tweet'] = data_processed['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        !!! rt @mayasolovely: as a woman you shouldn't...\n",
       "1        !!!!! rt @mleew17: boy dats cold...tyga dwn ba...\n",
       "2        !!!!!!! rt @urkindofbrand dawg!!!! rt @80sbaby...\n",
       "3        !!!!!!!!! rt @c_g_anderson: @viva_based she lo...\n",
       "4        !!!!!!!!!!!!! rt @shenikaroberts: the shit you...\n",
       "                               ...                        \n",
       "24778    you's a muthaf***in lie &#8220;@lifeasking: @2...\n",
       "24779    you've gone and broke the wrong heart baby, an...\n",
       "24780    young buck wanna eat!!.. dat nigguh like i ain...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782    ~~ruffled | ntac eileen dahlia - beautiful col...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lowercase removal\n",
    "data_processed['tweet'] = data_processed['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "data_processed['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/2353336898.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data_processed['tweet'] = data_processed['tweet'].str.replace('[^\\w\\s]','')\n",
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/2353336898.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_processed['tweet'] = data_processed['tweet'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         rt mayasolovely as a woman you shouldnt compl...\n",
       "1         rt mleew17 boy dats coldtyga dwn bad for cuff...\n",
       "2         rt urkindofbrand dawg rt 80sbaby4life you eve...\n",
       "3         rt c_g_anderson viva_based she look like a tr...\n",
       "4         rt shenikaroberts the shit you hear about me ...\n",
       "                               ...                        \n",
       "24778    yous a muthafin lie 8220lifeasking 20_pearls c...\n",
       "24779    youve gone and broke the wrong heart baby and ...\n",
       "24780    young buck wanna eat dat nigguh like i aint fu...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782    ruffled  ntac eileen dahlia  beautiful color c...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Punctuation Removal\n",
    "data_processed['tweet'] = data_processed['tweet'].str.replace('[^\\w\\s]','')\n",
    "data_processed['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/3867049835.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', ' ', x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         rt mayasolovely as woman you shouldnt complai...\n",
       "1         rt mleew17 boy dats coldtyga dwn bad for cuff...\n",
       "2         rt urkindofbrand dawg rt 80sbaby4life you eve...\n",
       "3          rt c_g_anderson viva_based she look like tranny\n",
       "4         rt shenikaroberts the shit you hear about me ...\n",
       "                               ...                        \n",
       "24778    yous muthafin lie 8220lifeasking 20_pearls cor...\n",
       "24779    youve gone and broke the wrong heart baby and ...\n",
       "24780    young buck wanna eat dat nigguh like aint fuck...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782    ruffled  ntac eileen dahlia  beautiful color c...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single character and double space removal (a/i/n etc)\n",
    "data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', ' ', x))\n",
    "data_processed['tweet'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/3113575936.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r'@\\w+', '', x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         rt mayasolovely as woman you shouldnt complai...\n",
       "1         rt mleew17 boy dats coldtyga dwn bad for cuff...\n",
       "2         rt urkindofbrand dawg rt 80sbaby4life you eve...\n",
       "3          rt c_g_anderson viva_based she look like tranny\n",
       "4         rt shenikaroberts the shit you hear about me ...\n",
       "                               ...                        \n",
       "24778    yous muthafin lie 8220lifeasking 20_pearls cor...\n",
       "24779    youve gone and broke the wrong heart baby and ...\n",
       "24780    young buck wanna eat dat nigguh like aint fuck...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782    ruffled  ntac eileen dahlia  beautiful color c...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove usernames/handles \n",
    "data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r'@\\w+', '', x))\n",
    "data_processed['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/643837315.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_processed['tweet'] = data_processed['tweet'].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         rt mayasolovely as woman you shouldnt complai...\n",
       "1         rt mleew17 boy dats coldtyga dwn bad for cuff...\n",
       "2         rt urkindofbrand dawg rt 80sbaby4life you eve...\n",
       "3          rt c_g_anderson viva_based she look like tranny\n",
       "4         rt shenikaroberts the shit you hear about me ...\n",
       "                               ...                        \n",
       "24778    yous muthafin lie 8220lifeasking 20_pearls cor...\n",
       "24779    youve gone and broke the wrong heart baby and ...\n",
       "24780    young buck wanna eat dat nigguh like aint fuck...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782    ruffled  ntac eileen dahlia  beautiful color c...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove emojis\n",
    "data_processed['tweet'] = data_processed['tweet'].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
    "data_processed['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing emojis, usernames/handles, single charters, double spaces, punctuations, lowercases and URLs, the most common words are generated to understand what is the most common words amongst tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bitch      8120\n",
       "rt         7578\n",
       "the        7168\n",
       "you        6075\n",
       "to         5332\n",
       "and        3950\n",
       "my         3576\n",
       "that       3515\n",
       "in         3049\n",
       "bitches    3045\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common words\n",
    "freq = pd.Series(' '.join(data_processed['tweet']).split()).value_counts()[:10]\n",
    "freq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be noted that the words/symbols 'rt' and ':' are the most common among the tweets. These two words/symbols are of no benefit for this dataset and do not contribute to the analysis of hate speech. The term 'rt' is used in twitter to say retweet which is the action of re posting a twitter post and the semicolon, :, can be used for gramatical purposes. \n",
    "\n",
    "For this analysis, \"rt\" and the \":\" symbol are not needed, so we can remove them as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/48207569.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r'rt', '', x))\n",
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/48207569.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r':', '', x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          mayasolovely as woman you shouldnt complain ...\n",
       "1          mleew17 boy dats coldtyga dwn bad for cuffin...\n",
       "2          urkindofbrand dawg  80sbaby4life you ever fu...\n",
       "3             c_g_anderson viva_based she look like tranny\n",
       "4          shenikarobes the shit you hear about me migh...\n",
       "                               ...                        \n",
       "24778    yous muthafin lie 8220lifeasking 20_pearls cor...\n",
       "24779    youve gone and broke the wrong hea baby and dr...\n",
       "24780    young buck wanna eat dat nigguh like aint fuck...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782    ruffled  ntac eileen dahlia  beautiful color c...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the words rt and :\n",
    "data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r'rt', '', x))\n",
    "data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r':', '', x))\n",
    "data_processed['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bitch      8120\n",
       "the        7168\n",
       "you        6075\n",
       "to         5332\n",
       "and        3950\n",
       "my         3576\n",
       "that       3515\n",
       "in         3050\n",
       "bitches    3045\n",
       "is         2909\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the most common words\n",
    "freq = pd.Series(' '.join(data_processed['tweet']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the most common words the list only displays words however there are still special characters in the data which will interfere with the analysis, so we can remove those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/4181547221.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r'[^a-zA-Z\\s]', '', x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          mayasolovely as woman you shouldnt complain ...\n",
       "1          mleew boy dats coldtyga dwn bad for cuffin d...\n",
       "2          urkindofbrand dawg  sbabylife you ever fuck ...\n",
       "3                cganderson vivabased she look like tranny\n",
       "4          shenikarobes the shit you hear about me migh...\n",
       "                               ...                        \n",
       "24778    yous muthafin lie lifeasking pearls coreyemanu...\n",
       "24779    youve gone and broke the wrong hea baby and dr...\n",
       "24780    young buck wanna eat dat nigguh like aint fuck...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782    ruffled  ntac eileen dahlia  beautiful color c...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove special and numeric characters\n",
    "data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "data_processed['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/689008908.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r'\\s+', ' ', x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         mayasolovely as woman you shouldnt complain a...\n",
       "1         mleew boy dats coldtyga dwn bad for cuffin da...\n",
       "2         urkindofbrand dawg sbabylife you ever fuck bi...\n",
       "3                cganderson vivabased she look like tranny\n",
       "4         shenikarobes the shit you hear about me might...\n",
       "                               ...                        \n",
       "24778    yous muthafin lie lifeasking pearls coreyemanu...\n",
       "24779    youve gone and broke the wrong hea baby and dr...\n",
       "24780    young buck wanna eat dat nigguh like aint fuck...\n",
       "24781                youu got wild bitches tellin you lies\n",
       "24782    ruffled ntac eileen dahlia beautiful color com...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove any double spaces\n",
    "data_processed['tweet'] = data_processed['tweet'].apply(lambda x:re.sub(r'\\s+', ' ', x))\n",
    "data_processed['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ceyda/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally stopwords can be removed to only display keywords which may be curcial in identifying hate speech, offensive langauge tweets in datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/vpq71tdd6t7d2hvqqzjsv3vr0000gn/T/ipykernel_1162/3851837317.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_processed['tweet'] = data_processed['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        mayasolovely woman shouldnt complain cleaning ...\n",
       "1        mleew boy dats coldtyga dwn bad cuffin dat hoe...\n",
       "2        urkindofbrand dawg sbabylife ever fuck bitch s...\n",
       "3                    cganderson vivabased look like tranny\n",
       "4        shenikarobes shit hear might true might faker ...\n",
       "                               ...                        \n",
       "24778    yous muthafin lie lifeasking pearls coreyemanu...\n",
       "24779    youve gone broke wrong hea baby drove redneck ...\n",
       "24780    young buck wanna eat dat nigguh like aint fuck...\n",
       "24781                    youu got wild bitches tellin lies\n",
       "24782    ruffled ntac eileen dahlia beautiful color com...\n",
       "Name: tweet, Length: 24783, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "stop = stopwords.words('english')\n",
    "data_processed['tweet'] = data_processed['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "data_processed['tweet']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning twitterhate.csv As A Test set \n",
    "\n",
    "The above process can now be applied on the twitterhate.csv file which can be used as the test set which will assist in anomly detction for misinformation/hate speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  label                                              tweet\n",
      "0   1      0   @user when a father is dysfunctional and is s...\n",
      "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
      "2   3      0                                bihday your majesty\n",
      "3   4      0  #model   i love u take with u all the time in ...\n",
      "4   5      0             factsguide: society now    #motivation\n",
      "Index(['id', 'label', 'tweet'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the TwitterHate dataset\n",
    "twitter_hate_data = pd.read_csv('TwitterHate.csv')\n",
    "\n",
    "# Display the first few rows of the TwitterHate dataset to inspect its structure\n",
    "print(twitter_hate_data.head())\n",
    "\n",
    "# Display the column names to check what keys are available for merging\n",
    "print(twitter_hate_data.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Dataset \n",
    "\n",
    "- The twitterhate.csv file is loaded into the variable name twitter_hate_data. This is then used to condut initial analysis on the data.\n",
    "- The variables on this csv file are id, label and tweet. \n",
    "\n",
    "Below is a list explaining each variable \n",
    "- label: CLasifies the data as either 0 or 1, 0: Non-hate, 1:Hate speech (Integer) </br>\n",
    "- tweet: The tweet which the classficiations are being made on (String) </br>\n",
    "\n",
    "NOTE: The id column looks to be an index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter Hate Data first 10 rows:\n",
      "   id  label                                              tweet\n",
      "0   1      0   @user when a father is dysfunctional and is s...\n",
      "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
      "2   3      0                                bihday your majesty\n",
      "3   4      0  #model   i love u take with u all the time in ...\n",
      "4   5      0             factsguide: society now    #motivation\n",
      "5   6      0  [2/2] huge fan fare and big talking before the...\n",
      "6   7      0   @user camping tomorrow @user @user @user @use...\n",
      "7   8      0  the next school year is the year for exams....\n",
      "8   9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
      "9  10      0   @user @user welcome here !  i'm   it's so #gr...\n",
      "\n",
      "Twitter Hate Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the 2nd dataset\n",
    "print(\"\\nTwitter Hate Data first 10 rows:\")\n",
    "print(twitter_hate_data.head(10))\n",
    "\n",
    "# Check the structure and column names\n",
    "print(\"\\nTwitter Hate Data Info:\")\n",
    "print(twitter_hate_data.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter Hate Data Description:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31962.000000</td>\n",
       "      <td>31962.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15981.500000</td>\n",
       "      <td>0.070146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9226.778988</td>\n",
       "      <td>0.255397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7991.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15981.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23971.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>31962.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         label\n",
       "count  31962.000000  31962.000000\n",
       "mean   15981.500000      0.070146\n",
       "std     9226.778988      0.255397\n",
       "min        1.000000      0.000000\n",
       "25%     7991.250000      0.000000\n",
       "50%    15981.500000      0.000000\n",
       "75%    23971.750000      0.000000\n",
       "max    31962.000000      1.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nTwitter Hate Data Description:\")\n",
    "twitter_hate_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the statistical data analysis (ignoring the id column) it can be said that:\n",
    "\n",
    "- Label: The mean of 0.07 indictaes that 7% of the tweets are classfied as hate speech. A standard deviation of 0.26 can reflect most of the values in the coloumn being close to the mean. At least 75% of the data is not classfied as hate speech as the 25th, 50th and 75th percentile are all 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Twitter Hate Data:\n",
      "id       0\n",
      "label    0\n",
      "tweet    0\n",
      "dtype: int64\n",
      "\n",
      "Duplicated values in Twitter Hate Data:\n",
      "0\n",
      "\n",
      "N/a values in Twitter Hate Data:\n",
      "id       0\n",
      "label    0\n",
      "tweet    0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in 'label' column (Twitter Hate Data):\n",
      "[0 1]\n",
      "\n",
      "Value counts for 'label' in Twitter Hate Data:\n",
      "0    29720\n",
      "1     2242\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in Twitter Hate Data:\")\n",
    "print(twitter_hate_data.isnull().sum())\n",
    "\n",
    "#Check for duplicated values \n",
    "print(\"\\nDuplicated values in Twitter Hate Data:\")\n",
    "print(twitter_hate_data.duplicated().sum())\n",
    "\n",
    "#Check for nas in the dataset\n",
    "print(\"\\nN/a values in Twitter Hate Data:\")\n",
    "print(twitter_hate_data.isna().sum())\n",
    "\n",
    "# Get unique values in categorical columns (e.g., 'class' and 'label')\n",
    "print(\"\\nUnique values in 'label' column (Twitter Hate Data):\")\n",
    "print(twitter_hate_data['label'].unique())\n",
    "\n",
    "# Value counts for each label\n",
    "print(\"\\nValue counts for 'label' in Twitter Hate Data:\")\n",
    "print(twitter_hate_data['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has no missing values, only 0 or 1 values in the label column and a total of 31,962 tweets. \n",
    "Additionally the dataset has no duplicated values or n/a values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing PART 2\n",
    "\n",
    "- The data preprocessing stage is important to turn the raw data (twitterhate.csv) into clean data that can then be used for training and testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps that must be taken after the intial data analysis is data preprocessing. Here the dataset is taken and the following elements are removed from the dataset: \n",
    "\n",
    "- urls\n",
    "- usernames (especially for anonymity)\n",
    "- emojis\n",
    "- punctuation\n",
    "- single characters + double spaces\n",
    "\n",
    "The following are processed to ensure clarity in the data:\n",
    "\n",
    "- Turning everything lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in Twitter Hate Data:\n",
      " user    17495\n",
      "the     10192\n",
      "to       9843\n",
      "you      5456\n",
      "and      4895\n",
      "in       4653\n",
      "for      4496\n",
      "is       4185\n",
      "of       4178\n",
      "my       3691\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing for the 'tweet' column (Twitter Hate Data)\n",
    "twitter_hate_data['tweet'] = twitter_hate_data['tweet'].apply(lambda x: re.sub(r'https?://\\S+', '', x))  # remove URLs\n",
    "twitter_hate_data['tweet'] = twitter_hate_data['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))  # lowercase\n",
    "twitter_hate_data['tweet'] = twitter_hate_data['tweet'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))  # remove punctuation\n",
    "twitter_hate_data['tweet'] = twitter_hate_data['tweet'].apply(lambda x: re.sub(r'\\s+[a-zA-Z]\\s+', ' ', x))  # remove single characters\n",
    "twitter_hate_data['tweet'] = twitter_hate_data['tweet'].apply(lambda x: re.sub(r'@\\w+', '', x))  # remove usernames\n",
    "twitter_hate_data['tweet'] = twitter_hate_data['tweet'].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))  # remove emojis\n",
    "twitter_hate_data['tweet'] = twitter_hate_data['tweet'].apply(lambda x:re.sub(r'\\s+', ' ', x))  # remove double spaces\n",
    "\n",
    "# Most common words in Twitter Hate Data\n",
    "freq_twitter_hate = pd.Series(' '.join(twitter_hate_data['tweet']).split()).value_counts()[:10]\n",
    "print(\"Most common words in Twitter Hate Data:\\n\", freq_twitter_hate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing emojis, usernames/handles, single charters, double spaces, punctuations, lowercases and URLs, the most common words are generated to understand what is the most common words amongst tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    user father dysfunctional selfish drags kids d...\n",
      "1    user user thanks lyft credit cant use cause do...\n",
      "2                                       bihday majesty\n",
      "3                              model love take time ur\n",
      "4                        factsguide society motivation\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "twitter_hate_data['tweet'] = twitter_hate_data['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "# Display the cleaned dataset for verification\n",
    "print(twitter_hate_data['tweet'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally stopwords can be removed to only display keywords which may be curcial in identifying hate speech, offensive langauge tweets in datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    father dysfunctional selfish drags kids dysfun...\n",
      "1    thanks lyft credit cant use cause dont offer w...\n",
      "2                                       bihday majesty\n",
      "3                              model love take time ur\n",
      "4                        factsguide society motivation\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# add an additional stopword 'user' to remove from twitter hate data\n",
    "stop.append('user')\n",
    "twitter_hate_data['tweet'] = twitter_hate_data['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "# Display the cleaned dataset for verification\n",
    "print(twitter_hate_data['tweet'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words in Twitter Hate Data:\n",
      " love     2725\n",
      "day      2253\n",
      "happy    1691\n",
      "amp      1601\n",
      "im       1156\n",
      "life     1126\n",
      "time     1126\n",
      "like     1052\n",
      "today    1004\n",
      "new       988\n",
      "dtype: int64\n",
      "          id  label                                              tweet\n",
      "6          7      0                             camping tomorrow danny\n",
      "8          9      0  love land allin cavs champions cleveland cleve...\n",
      "22        23      0  product day happy man wine tool whos weekend t...\n",
      "64        65      0  wife adore miss poland show surgery name bridg...\n",
      "73        74      0  ferrari sake championship gp clearly turning p...\n",
      "...      ...    ...                                                ...\n",
      "31867  31868      0                     want cereal amp aint tryna get\n",
      "31881  31882      0  please like amp share agree dna dnaquotes quot...\n",
      "31933  31934      1  judd amp homophobic freemilo milo freemilo mil...\n",
      "31935  31936      0  ugh im trying enjoy happy hour drink amp talks...\n",
      "31942  31943      0            week flying humpday wednesday kamp ucsd\n",
      "\n",
      "[1907 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# check frequent words\n",
    "freq_twitter_hate = pd.Series(' '.join(twitter_hate_data['tweet']).split()).value_counts()[:10]\n",
    "# check the most common words\n",
    "print(\"Most common words in Twitter Hate Data:\\n\", freq_twitter_hate)\n",
    "# filter rows where the word 'amp' is present in the tweet column and like see if it is 1 word or part of another word\n",
    "print(twitter_hate_data[twitter_hate_data['tweet'].str.contains('amp')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22                           product day happy man wine tool whos weekend time open amp drink\n",
      "64                       wife adore miss poland show surgery name bridget amp shes everything\n",
      "82                                       altright uses amp insecurity lure men whitesupremacy\n",
      "111    im interested linguistics doesnt address race amp racism power raciolinguistics brings\n",
      "163                                                                  soed nut amp bolts bloke\n",
      "Name: tweet, dtype: object\n",
      "Most common words in Twitter Hate Data:\n",
      " love        2725\n",
      "day         2253\n",
      "happy       1691\n",
      "im          1156\n",
      "life        1126\n",
      "time        1126\n",
      "like        1052\n",
      "today       1004\n",
      "new          988\n",
      "positive     934\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# show 5 rows where the word 'amp' is present in the tweet column and display the tweet column, 1 easy way to check if 'amp' is a separate word or part of another word\n",
    "# is by regex if there is a space before and after the word 'amp' then it is a separate word\n",
    "# Adjust pandas settings to display full content of the cell\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(twitter_hate_data[twitter_hate_data['tweet'].str.contains(r'\\samp\\s')]['tweet'].head())\n",
    "   \n",
    "\n",
    "# add an additional stopword 'amp' to remove from twitter hate data\n",
    "stop.append('amp')\n",
    "twitter_hate_data['tweet'] = twitter_hate_data['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "# check frequent words\n",
    "freq_twitter_hate = pd.Series(' '.join(twitter_hate_data['tweet']).split()).value_counts()[:10]\n",
    "# check the most common words\n",
    "print(\"Most common words in Twitter Hate Data:\\n\", freq_twitter_hate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the most common words list for twitterhate.csv the word 'amp' was the fourth most common word amongst 31,962 tweets. To ensure that amp wasnt apart of another word which may disrupt the flow of the tweet and thus removing crucial information and signifcance the first five rows were analised of where amp appears. This ensured that amp was in fact a word on its own and not apart of another word. This word is added to the stopword list which allows space for another more common word that carries more meaning and will assist in the testing and training of this project. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
